{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsbtorch import IterableVideoSlidingWindowDataset, VideoSlidingWindowDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pathlib\n",
    "import pickle\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "torchvision.set_image_backend('accimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = transforms.Compose([\n",
    "    transforms.Resize((144, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/home/ubuntu/data/dataset/\"\n",
    "# data_dir = \"/home/ubuntu/data/dataset_511/\"\n",
    "# data_dir = \"/home/ubuntu/data/toy_dataset/\"\n",
    "sampling_rate = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['train', 'dev'] #, 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1\n",
    "positive_sampling_rate = sampling_rate\n",
    "negative_sampling_rate = 10 * sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanned_datasets = {}\n",
    "for x in dataset_names:\n",
    "    sddir = pathlib.Path(\"scans/\" + os.path.join(data_dir, x))\n",
    "    sdfile = sddir / (\"ws%d-psr%d-nsr%d.pkl\" % (window_size, positive_sampling_rate, negative_sampling_rate))\n",
    "    print(sdfile)\n",
    "    if not sdfile.exists():\n",
    "        raise ValueError(\"You need to use the ScanDatasets notebook first to scan & pickle the dataset.\")\n",
    "    with open(sdfile, 'rb') as f:\n",
    "        scanned_datasets[x] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {x: VideoSlidingWindowDataset(scanned_datasets[x], t) for x in dataset_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example count: 4616\n"
     ]
    }
   ],
   "source": [
    "print(\"Training example count: %d\" % len(datasets['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=batch_size, num_workers=6, pin_memory=True) for x in dataset_names}\n",
    "dataset_sizes = {x: len(datasets[x]) for x in dataset_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_totals(preds, labels, tp, tn, fp, fn):\n",
    "    tp += torch.sum((preds == labels) * (labels == 1)).item()\n",
    "    tn += torch.sum((preds == labels) * (labels == 0)).item()\n",
    "    fp += torch.sum((preds != labels) * (labels == 0)).item()\n",
    "    fn += torch.sum((preds != labels) * (labels == 1)).item()\n",
    "    return (tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, output_path, num_epochs=25, beta2=0.25, print_every_n=0, writer=None, hyperparams=None):\n",
    "    writer = SummaryWriter(comment=\"sr%d-%s-lr%d-decay%d.weights\" % (sampling_rate, hyperparams['optimizer'], int(hyperparams['learning_rate'] * 1000), int(hyperparams['lr_decay'])))\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_fscore = 0.0\n",
    "    \n",
    "    epoch_loss = {}\n",
    "    epoch_fscore = {}\n",
    "    epoch_accuracy = {}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('\\n\\nEpoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'dev']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                print('\\nTraining phase.')\n",
    "                print('-' * 8)\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                print('\\nEvaluation phase.')\n",
    "                print('-' * 8)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "            i = 0\n",
    "            batch_start = time.time()\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:                        \n",
    "                inputs = torch.reshape(inputs, (-1, 3, 144, 256))\n",
    "                inputs = inputs.to(device)\n",
    "                labels = torch.reshape(labels, (-1, ))\n",
    "                labels = labels.long()\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                tp, tn, fp, fn = running_totals(preds, labels.data, tp, tn, fp, fn)\n",
    "                \n",
    "                if (print_every_n > 0 and i % print_every_n == 0 and i > 0) or i == len(dataloaders[phase]) - 1:\n",
    "                    td = time.time() - batch_start\n",
    "                    print(\"Batch number \", i)\n",
    "                    print(\"Total images used this epoch: \", batch_size * print_every_n)\n",
    "                    print(\"Statistics: \", tp, tn, fp, fn)\n",
    "                    print(\"Time since last update: \", td)\n",
    "                    print(\"Time per 1000 images:\", td * 1000 / (batch_size * print_every_n))\n",
    "                    batch_start = time.time()\n",
    "\n",
    "                i += 1\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss[phase] = running_loss / dataset_sizes[phase]\n",
    "            epoch_fscore[phase] = (1 + beta2) * tp / ((1 + beta2) * tp + beta2 * fn + fp)\n",
    "            epoch_accuracy[phase] = (tp + tn) / (tp + tn + fp + fn)\n",
    "            \n",
    "            writer.add_scalar(\"Loss/\" + phase, epoch_loss[phase], epoch)\n",
    "            writer.add_scalar(\"FScore/\" + phase, epoch_fscore[phase], epoch)\n",
    "            writer.add_scalar(\"Accuracy/\" + phase, epoch_accuracy[phase], epoch)\n",
    "\n",
    "            print('{} Loss: {:.4f} F0.5: {:.4f}  Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss[phase], epoch_fscore[phase], epoch_accuracy[phase]))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'dev' and epoch_fscore[phase] > best_fscore:\n",
    "                best_fscore = epoch_fscore[phase]\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, output_path + str(epoch))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val F score: {:4f}'.format(best_fscore))\n",
    "    \n",
    "    if hyperparams:\n",
    "        writer.add_hparams(\n",
    "            hyperparams,\n",
    "            {\n",
    "                \"H-Loss/Train\": epoch_loss['train'],\n",
    "                \"H-Loss/Dev\": epoch_loss['dev'],\n",
    "                \"H-FScore/Train\": epoch_fscore['train'],\n",
    "                \"H-FScore/Dev\": epoch_fscore['dev'],\n",
    "                \"H-Accuracy/Train\": epoch_accuracy['train'],\n",
    "                \"H-Accuracy/Dev\": epoch_accuracy['dev'],\n",
    "            })\n",
    "        \n",
    "    writer.close()\n",
    "\n",
    "    # Save and load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), output_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 0/0\n",
      "----------\n",
      "\n",
      "Training phase.\n",
      "--------\n",
      "Batch number  9\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 2796 423 1397\n",
      "Time since last update:  28.887014627456665\n",
      "Time per 1000 images: 1.128399008885026\n",
      "train Loss: 3419.6910 F0.5: 0.0000  Acc: 0.6057\n",
      "\n",
      "Evaluation phase.\n",
      "--------\n",
      "Batch number  0\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 320 0 142\n",
      "Time since last update:  1.6115942001342773\n",
      "Time per 1000 images: 0.06295289844274521\n",
      "dev Loss: 78454071296.0000 F0.5: 0.0000  Acc: 0.6926\n",
      "Training complete in 0m 31s\n",
      "Best val F score: 0.000000\n",
      "\n",
      "\n",
      "Epoch 0/0\n",
      "----------\n",
      "\n",
      "Training phase.\n",
      "--------\n",
      "Batch number  9\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 2957 262 1397\n",
      "Time since last update:  27.366166591644287\n",
      "Time per 1000 images: 1.068990882486105\n",
      "train Loss: 3393.1413 F0.5: 0.0000  Acc: 0.6406\n",
      "\n",
      "Evaluation phase.\n",
      "--------\n",
      "Batch number  0\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 320 0 142\n",
      "Time since last update:  1.620054006576538\n",
      "Time per 1000 images: 0.06328335963189602\n",
      "dev Loss: 305034297344.0000 F0.5: 0.0000  Acc: 0.6926\n",
      "Training complete in 0m 29s\n",
      "Best val F score: 0.000000\n",
      "\n",
      "\n",
      "Epoch 0/0\n",
      "----------\n",
      "\n",
      "Training phase.\n",
      "--------\n",
      "Batch number  9\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 2837 382 1397\n",
      "Time since last update:  27.76195788383484\n",
      "Time per 1000 images: 1.0844514798372984\n",
      "train Loss: 51.3304 F0.5: 0.0000  Acc: 0.6146\n",
      "\n",
      "Evaluation phase.\n",
      "--------\n",
      "Batch number  0\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 320 0 142\n",
      "Time since last update:  1.643855333328247\n",
      "Time per 1000 images: 0.06421309895813465\n",
      "dev Loss: 5904028672.0000 F0.5: 0.0000  Acc: 0.6926\n",
      "Training complete in 0m 30s\n",
      "Best val F score: 0.000000\n",
      "\n",
      "\n",
      "Epoch 0/0\n",
      "----------\n",
      "\n",
      "Training phase.\n",
      "--------\n",
      "Batch number  9\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 2886 333 1397\n",
      "Time since last update:  27.568902730941772\n",
      "Time per 1000 images: 1.076910262927413\n",
      "train Loss: 55.1921 F0.5: 0.0000  Acc: 0.6252\n",
      "\n",
      "Evaluation phase.\n",
      "--------\n",
      "Batch number  0\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 320 0 142\n",
      "Time since last update:  1.630918025970459\n",
      "Time per 1000 images: 0.06370773538947105\n",
      "dev Loss: 436948608.0000 F0.5: 0.0000  Acc: 0.6926\n",
      "Training complete in 0m 29s\n",
      "Best val F score: 0.000000\n",
      "\n",
      "\n",
      "Epoch 0/0\n",
      "----------\n",
      "\n",
      "Training phase.\n",
      "--------\n",
      "Batch number  9\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 3126 93 1397\n",
      "Time since last update:  27.697038412094116\n",
      "Time per 1000 images: 1.0819155629724264\n",
      "train Loss: 4.6040 F0.5: 0.0000  Acc: 0.6772\n",
      "\n",
      "Evaluation phase.\n",
      "--------\n",
      "Batch number  0\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 320 0 142\n",
      "Time since last update:  1.628922939300537\n",
      "Time per 1000 images: 0.06362980231642723\n",
      "dev Loss: 3813754.5000 F0.5: 0.0000  Acc: 0.6926\n",
      "Training complete in 0m 29s\n",
      "Best val F score: 0.000000\n",
      "\n",
      "\n",
      "Epoch 0/0\n",
      "----------\n",
      "\n",
      "Training phase.\n",
      "--------\n",
      "Batch number  9\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 2744 475 1397\n",
      "Time since last update:  27.882627487182617\n",
      "Time per 1000 images: 1.089165136218071\n",
      "train Loss: 5.3342 F0.5: 0.0000  Acc: 0.5945\n",
      "\n",
      "Evaluation phase.\n",
      "--------\n",
      "Batch number  0\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 320 0 142\n",
      "Time since last update:  1.6561551094055176\n",
      "Time per 1000 images: 0.06469355896115303\n",
      "dev Loss: 1880916.2500 F0.5: 0.0000  Acc: 0.6926\n",
      "Training complete in 0m 30s\n",
      "Best val F score: 0.000000\n",
      "\n",
      "\n",
      "Epoch 0/0\n",
      "----------\n",
      "\n",
      "Training phase.\n",
      "--------\n",
      "Batch number  9\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  7 2708 511 1390\n",
      "Time since last update:  27.82690668106079\n",
      "Time per 1000 images: 1.0869885422289371\n",
      "train Loss: 1.4930 F0.5: 0.0101  Acc: 0.5882\n",
      "\n",
      "Evaluation phase.\n",
      "--------\n",
      "Batch number  0\n",
      "Total images used this epoch:  25600\n",
      "Statistics:  0 320 0 142\n",
      "Time since last update:  1.6360583305358887\n",
      "Time per 1000 images: 0.06390852853655815\n",
      "dev Loss: 115.9638 F0.5: 0.0000  Acc: 0.6926\n",
      "Training complete in 0m 30s\n",
      "Best val F score: 0.000000\n",
      "\n",
      "\n",
      "Epoch 0/0\n",
      "----------\n",
      "\n",
      "Training phase.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 21\n",
    "\n",
    "for optname in ['adam', 'sgd']:\n",
    "    for lr in [1.0, 0.1, 0.01, 0.001]:\n",
    "        for decay in [True, False]:\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            # for param in model.parameters():\n",
    "            #     param.requires_grad = False\n",
    "\n",
    "            num_ftrs = model.fc.in_features\n",
    "            model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "            model = model.to(device)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            # Observe that all parameters are being optimized\n",
    "            if optname == 'adam':\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            else:\n",
    "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "            # Decay LR by a factor of 0.1 every 7 epochs\n",
    "            exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=(0.1 if decay else 1))\n",
    "            \n",
    "            hyperparams = {'optimizer': optname, 'learning_rate': lr, 'lr_decay': decay}\n",
    "\n",
    "            outpath = \"../results/search-sr%d-%s-lr%d-decay%d.weights\" % (sampling_rate, optimizer, int(lr * 1000), int(decay))\n",
    "            model = train_model(model, criterion, optimizer, exp_lr_scheduler, outpath, num_epochs=num_epochs, print_every_n=50, hyperparams=hyperparams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
